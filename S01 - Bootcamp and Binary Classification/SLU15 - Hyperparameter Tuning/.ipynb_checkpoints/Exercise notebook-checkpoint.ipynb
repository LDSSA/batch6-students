{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jc1eU_dVECIZ",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e37aef4d78b4c632",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# SLU15 - Hyperparameter Tuning : Exercise notebook\n",
    "\n",
    "### New concepts in this unit\n",
    "\n",
    "*  Hyperparameter definition\n",
    "*  Hyperparameter search\n",
    "*  Model selection\n",
    "\n",
    "### New tools in this unit\n",
    "- [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "- [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UpoBQazfOcdm",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-673e46abe486e6cf",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Introduction\n",
    "You decide you want to apply your data science skills to help identify the risk of heart disease in patients, and so decide to take a look at the [Heart Disease UCI ](https://archive.ics.uci.edu/ml/datasets/Heart+Disease)dataset. This database contains 76 attributes, but all published experiments refer to using a subset of 14 of them. You follow the example and load the simplified dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zvs-JlaoOqhB",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8c2e27bca8450438",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import warnings\n",
    "from hashlib import sha256\n",
    "import json\n",
    "\n",
    "import sklearn\n",
    "# These will be needed to prepare the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Cxy3SZa9Vl8-",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-af75adfcef8e3e25",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "d745d4af-91fe-47a4-840b-1f76b6dcfd25"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>178</td>\n",
       "      <td>228</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>227</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "167   66    0   3       178   228    1        0      165      1      1.0   \n",
       "211   59    1   3       140   177    0        0      162      1      0.0   \n",
       "63    41    1   1       135   203    0        0      132      0      0.0   \n",
       "154   37    0   2       120   215    0        0      170      0      0.0   \n",
       "5     64    1   0       170   227    0        2      155      0      0.6   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "167      1   2     2       1  \n",
       "211      0   1     2       1  \n",
       "63       1   0     1       0  \n",
       "154      0   0     0       0  \n",
       "5        1   0     2       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Load data\n",
    "heart_df = pd.read_csv(\"data/heart.csv\").rename({\"condition\":\"target\"}, axis=1)\n",
    "heart_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qRj_iSssTcLg",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f1b446af2ec6ae5f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "You then train-test split your dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Anbcj4COS7nK",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fabf478785185daf",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        heart_df.drop(\"target\", axis=1),\n",
    "                                        heart_df.target, \n",
    "                                        test_size=0.3,\n",
    "                                        random_state=42\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QTatcWRNOq8Q",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-326b4d912edd7888",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "You notice that the target variable is binary, as the patient either has a heart disease or not, and thus you recognize you are dealing with a  classification problem. Remembering the amazing class you had about Logistic Regression, you decide to use this classifier as a first approach. This  means that it is a good idea to scale your observations to have zero mean and unit standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "ZTWm0Jq1U5Wg",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c2413002e48ee6f8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "ee0e6fb4-66fe-4cb1-9e99-0d5fab0d2a13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train of shape  (207, 13)\n",
      "y_train of shape  (207,)\n",
      "X_test of shape   (90, 13)\n",
      "y_test of shape   (90,)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression is not scale invariant, so you scale your data beforehand\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"X_train of shape \", X_train.shape)\n",
    "print(\"y_train of shape \", y_train.shape)\n",
    "print(\"X_test of shape  \", X_test.shape)\n",
    "print(\"y_test of shape  \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8ab26b376b2d6c05",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 0 - Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7a64d3f597699253",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Start by creating a baseline. How good is a standard Logistic Regression classifier? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-da04d7a13e42a59d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Logistic Regression classifier with the default hyperparameters,\n",
    "# assign it to a variable called lr, and then fit it to the train data \n",
    "# lr=...\n",
    "\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "### END SOLUTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8ed72098d1377f2c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(lr, sklearn.linear_model.LogisticRegression)\n",
    "default_roc_auc_score=roc_auc_score(lr.predict(X_test), y_test)\n",
    "np.testing.assert_almost_equal(default_roc_auc_score, 0.788, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5ab9824e4c226652",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUROC score of the baseline Logistic regression classifier is  0.7888888888888889\n"
     ]
    }
   ],
   "source": [
    "print(\"The AUROC score of the baseline Logistic regression classifier is \", default_roc_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f92fc0db52773124",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The baseline score is ok, but you wonder if you could get better performance with this classifier. So, you decide to do some hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7eQkWwv-Elxa",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6ca133b5766a78ff",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 1- Grid Search\n",
    "\n",
    "Since you are not entirely sure what hyperparameters to choose, you decide to run a grid search to start with.\n",
    "\n",
    "1.1) Create a hyperparameter search space  with the following specifications:\n",
    "- Regularization parameter 'C' of 0.1, 1, 4, 8 and 10\n",
    "- penalty: \"l1\", \"l2\" and \"elasticnet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vTRk97yhpsQC",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7bae1466cae03dfa",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a hyperparameter search space  with the following specifications:\n",
    "# - 'C' of 0.1, 1, 4, 8 and 10\n",
    "# - penalty: \"l1\", \"l2\" and \"elasticnet\"\n",
    "# assign your grid to the variable grid\n",
    "# grid = ...\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "grid = {\"C\": (0.1, 1, 4, 8, 10), \"penalty\": (\"l2\", \"l1\", \"elasticnet\")}\n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "78i0emuGM22J",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-74b192f294d472a6",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(grid, dict), 'Make sure you are using a dictionary for your grid parameters'\n",
    "assert \"C\" in grid, 'Make sure you have the requested parameters as keys'\n",
    "assert \"penalty\" in grid, 'Make sure you have the requested parameters as keys'\n",
    "assert all(num in grid[\"C\"] for num in [0.1, 1, 4, 8, 10]), 'The values for C parameter are not correct'\n",
    "assert \"l2\" in grid[\"penalty\"], 'The values for penalty parameter are not correct'\n",
    "assert \"l1\" in grid[\"penalty\"], 'The values for penalty parameter are not correct'\n",
    "assert \"elasticnet\" in grid[\"penalty\"], 'The values for penalty parameter are not correct'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bT7t3PeoHxd8",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-697bd760cb114938",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "1.2) Create a gridsearch with a Logistic Regression using the hyperparameter space defined in 1.1. Set the scoring function as the AUROC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AC891dnTH3Ky",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-839764842b89da11",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "54acbcc7-4fcb-47fb-d83f-3cfe3093ab9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoring hash 0aa8f1817e367c7a5a0556519f3332ef9499e96db9f0c5abb56adab073631d56\n"
     ]
    }
   ],
   "source": [
    "# Create a gridsearch with a Logistic Regression \n",
    "# use the hyperparameter space defined in 1.1\n",
    "# Set the scoring function as the AUROC \n",
    "# assign the gridsearch to the variable grid_search\n",
    "# grid_search = ...\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(LogisticRegression(), grid, scoring=\"roc_auc\")\n",
    "\n",
    "print(\"scoring hash\", \n",
    "      sha256(json.dumps(grid_search.get_params()[\"scoring\"]).encode()).hexdigest()\n",
    "     )\n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sN_VU6RpM1gQ",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-454d9120b621dcc9",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "scoring_hash='0aa8f1817e367c7a5a0556519f3332ef9499e96db9f0c5abb56adab073631d56'\n",
    "\n",
    "assert isinstance(grid_search, sklearn.model_selection.GridSearchCV), 'Are you using GridSearchCV?'\n",
    "assert isinstance(grid_search.estimator, sklearn.linear_model.LogisticRegression), 'Are you using the right model'\n",
    "assert scoring_hash == sha256(\n",
    "                        json.dumps(grid_search.get_params()[\"scoring\"]).encode()\n",
    "                    ).hexdigest(), 'Your parameters are not correct'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BbOZacl7KYu1",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a82ab7b985f9b84a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "1.3). Find the best estimator using grid_serach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "o-eaeEA-KMTn",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d2c2b32305db901c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "16e0962b-d5af-4e78-ba76-3b904f2c7b1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model params hash be93249222ae4fb94bbe669b3c81885256fea04671b60dc0a0ecd4bb9fc42b86\n"
     ]
    }
   ],
   "source": [
    "# Find the best estimator using grid_search from 1.2\n",
    "# Begin by performing the grid search over the train data\n",
    "# Then, extract the best estimator and assign it to best_model\n",
    "# best_model = ...\n",
    " \n",
    "### BEGIN SOLUTION\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "hash_ = sha256(json.dumps(best_model.get_params()).encode()).hexdigest()\n",
    "print(\"best model params hash\", hash_)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "isLHHEHkcO6i",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c833a0e642626b02",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "best_params_hash = 'be93249222ae4fb94bbe669b3c81885256fea04671b60dc0a0ecd4bb9fc42b86'\n",
    "student_hash = sha256(json.dumps(best_model.get_params()).encode()).hexdigest()\n",
    "\n",
    "assert isinstance(best_model, sklearn.linear_model.LogisticRegression), 'Make sure you are using the right model'\n",
    "assert best_params_hash == student_hash, 'Your parameters are not correct'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lENX5ZzaLPNj",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-703cff13cba6dc1c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "1.4) Make predictions on the test set using the estimator with the best found parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MooQ2CUzLg9v",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d19340bba970bf48",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "0955c396-ade7-4afe-9e30-19091091ac90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds hash: 6f7d373ff044125e90b9e2577bc4c8cbfcaea8f62f8270fa32d74b517148afa1\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data \n",
    "# using the estimator with the best found parameters\n",
    "# Assign the predictions to the best_preds\n",
    "# best_preds = ...\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "best_preds = grid_search.predict(X_test)\n",
    "\n",
    "print(\"preds hash:\", sha256(best_preds).hexdigest())\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DYNG4BDEdzPn",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-cca4c94daa1f1bd1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "preds_hash = '6f7d373ff044125e90b9e2577bc4c8cbfcaea8f62f8270fa32d74b517148afa1'\n",
    "assert preds_hash == sha256(best_preds).hexdigest(), 'Your parameters are not correct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-434edd336c0518cf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUROC score of the best grid search Logistic regression classifier is  0.811111111111111\n"
     ]
    }
   ],
   "source": [
    "print(\"The AUROC score of the best grid search Logistic regression classifier is \", roc_auc_score(best_preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-06794e969be1e9f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Nice, the performance improved! Let's see if we can do even better with Random search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6GvdvJLR55Ok",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-be72385637b53b03",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 2 - Random Search \n",
    "\n",
    "\n",
    "2.1) Create a random search distribution with the following hyperparameter distribution,\n",
    "\n",
    "- Regularization parameter 'C' uniformly distributed between 0.1 and 10\n",
    "- penalty  \"l2\", \"l1\" or \"elasticnet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W9V-aI_95_mb",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9e55b42741f78f71",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a random search distribution with the\n",
    "# following hyperparameter distribution\n",
    "#- 'C' uniformly distributed between 0.1 and 10 (hint: use a scipy distribution)\n",
    "#- penalty  \"l2\", \"l1\" or \"elasticnet\"\n",
    "# assign it to random_grid\n",
    "# random_grid = ...\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "from scipy.stats import uniform\n",
    "random_grid = {\"C\": uniform(0.1, 10), \"penalty\": (\"l2\", \"l1\", \"elasticnet\")}\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "30crPizWOSy1",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a95e4715d3d0e17e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert \"C\" in random_grid, 'Make sure you have the requested parameters as keys'\n",
    "assert \"penalty\" in random_grid, 'Make sure you have the requested parameters as keys'\n",
    "assert isinstance(random_grid[\"C\"], scipy.stats._distn_infrastructure.rv_frozen), 'The values for C parameter are not correct'\n",
    "assert \"l2\" in random_grid[\"penalty\"], 'The values for penalty parameter are not correct'\n",
    "assert \"l1\" in random_grid[\"penalty\"], 'The values for penalty parameter are not correct'\n",
    "assert \"elasticnet\" in random_grid[\"penalty\"], 'The values for penalty parameter are not correct'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OkdtEC20NQT1",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1d92fd58e8e4e83e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "2.2) Create a random search over a  Logistic Regression estimator.\n",
    "* Set the random_state to 42\n",
    "* Set the number of iterations to 15\n",
    "* Set the scoring to AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JNBN-RT9OWXO",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6da83075a9663ae5",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "c5a47d2b-9ef8-4d4d-86ca-0d34fd48859b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoring hash 0aa8f1817e367c7a5a0556519f3332ef9499e96db9f0c5abb56adab073631d56\n"
     ]
    }
   ],
   "source": [
    "# Create a random search \n",
    "# - Use a Logistic Regression estimator\n",
    "# - Set the random_state to 42\n",
    "# - Set the number of iterations to 15\n",
    "# - Set the scoring to AUROC\n",
    "# - Use the random grid you created in 2.1\n",
    "# assign it to random_search\n",
    "# random_search = ...\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_search = RandomizedSearchCV(LogisticRegression(), \n",
    "                                   random_grid,\n",
    "                                   scoring=\"roc_auc\",\n",
    "                                   n_iter=15,\n",
    "                                   random_state=42)\n",
    "\n",
    "print(\"scoring hash\", \n",
    "      sha256(json.dumps(grid_search.get_params()[\"scoring\"]).encode()).hexdigest()\n",
    "     )\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ZJai0McPmtf",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-94cd192ba475e33d",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "scoring_hash='0aa8f1817e367c7a5a0556519f3332ef9499e96db9f0c5abb56adab073631d56'\n",
    "\n",
    "assert isinstance(random_search, sklearn.model_selection.RandomizedSearchCV), 'Are you using RandomizedSearchCV?'\n",
    "assert isinstance(random_search.estimator, sklearn.linear_model.LogisticRegression), 'Make sure you are using the right model'\n",
    "assert random_search.random_state==42, 'Check your random_state value'\n",
    "assert random_search.n_iter==15, 'Check n_iter value'\n",
    "assert scoring_hash == sha256(\n",
    "                            json.dumps(random_search.get_params()[\"scoring\"]).encode()\n",
    "                        ).hexdigest(), 'Your parameters are not correct'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bHdIbHyfhacT",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ac1d536e4152b7f4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "2.3) Get the best model from the random_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R0Ahh3v8e8yQ",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-af31b5d6621ed971",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "62043c63-31a9-43f5-b0ca-df5482967160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best random search params hash c2fbca42369c6609159487a711fb011cf55e626ed986aef10f6a0326c31b23ca\n"
     ]
    }
   ],
   "source": [
    "# Get the best model from the random search\n",
    "# Begin by performing the random search over the train data\n",
    "# Then extract the best estimator and assign it to rs_best_model\n",
    "# rs_best_model = ...\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "random_search.fit(X_train, y_train)\n",
    "rs_best_model = random_search.best_estimator_\n",
    "\n",
    "hash_ = sha256(json.dumps(rs_best_model.get_params()).encode()).hexdigest()\n",
    "print(\"best random search params hash\", hash_)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YR4BChm9h_d3",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-32edafc7acb11ff3",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "rs_best_model_hash ='c2fbca42369c6609159487a711fb011cf55e626ed986aef10f6a0326c31b23ca'\n",
    "assert isinstance(rs_best_model, sklearn.linear_model.LogisticRegression) , 'Make sure you are using the right model'\n",
    "assert rs_best_model_hash==sha256(json.dumps(rs_best_model.get_params()).encode()).hexdigest(), 'Your parameters are not correct'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HvQkbsTnPxoT",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7969cb3584199467",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    " 2.4) Get the best parameters of the random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HK-802hOP_GG",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5a0ff5d8aa97468d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "d2ca3be2-3f19-4b7c-c973-d0bb4a31b9c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best LR params hash f0844d10d0d606c4bedd3ec11eb58f7303fb633665df9b3855a45d84c7caa04b\n"
     ]
    }
   ],
   "source": [
    "# Get the best parameters (for which the AUROC score was higher)\n",
    "# of the random search and assign them to best_rs_params\n",
    "# best_rs_params = ...\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "best_rs_params = random_search.best_params_\n",
    "\n",
    "print(\"best LR params hash\",\n",
    "     sha256(json.dumps(best_rs_params).encode()).hexdigest()\n",
    "     )\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vyUcN9ICgYkc",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3ef6f227bb55f1ac",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "best_rs_params_hash = 'f0844d10d0d606c4bedd3ec11eb58f7303fb633665df9b3855a45d84c7caa04b'\n",
    "assert best_rs_params_hash == sha256(json.dumps(best_rs_params).encode()).hexdigest(), 'Your parameters are not correct' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a0e7467276d7d1fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUROC score of the best random search Logistic regression classifier is  0.7888888888888889\n"
     ]
    }
   ],
   "source": [
    "print(\"The AUROC score of the best random search Logistic regression classifier is \",roc_auc_score(random_search.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-05bd857a5a2383e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Looks like we have a winner: the model resulting from the grid search performed best!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise notebook - SLU18 (Hyperparameter tuning)",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
